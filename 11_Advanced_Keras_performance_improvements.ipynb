{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data =  (data - np.mean(data, axis=...)) / np.std(data, axis=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 깊이별 분리 합성곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 64\n",
    "width  = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,\n",
    "                                 activation='relu',\n",
    "                                 input_shape=(height, width, channels,)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPool2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_7 (Separabl (None, 62, 62, 32)        155       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 60, 60, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 28, 28, 64)        4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 26, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 11, 11, 64)        9408      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 9, 9, 128)         8896      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 38,949\n",
      "Trainable params: 38,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_images/model_plot5.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](model_images/model_plot5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵션을 수정하고 모델을 반복적으로 다시 훈련하여 선택 사항을 개선해야한다. 이것이 머신 러닝 엔지니어와 연구자들이 대부분의 시간을 쓰는 일이다. \n",
    "\n",
    "이를 기계에 위임하는 것이 더 낫다. 가능한 결정 공간을 자동적, 조직적, 규칙적 방법으로 탐색해야 한다. 가능성 있는 구조를 탐색해서 실제 가장 높은 성능을 내는 것을 찾아야한다. 하이퍼파라미터 자동화가 이에 관련된 분야이다.\n",
    "\n",
    "전형적인 하이퍼파라미터 최적화 과정은 다음과 같다.\n",
    "\n",
    "1. 일련의 하이퍼파라미터를 자동으로 선택한다.\n",
    "2. 선택된 하이퍼파라미터로 모델을 만든다.\n",
    "3. 훈련 데이터에 학습하고 검증 데이터에서 최종 성능을 측정한다.\n",
    "4. 다음으로 시도할 하이퍼파라미터를 자동으로 선택한다.\n",
    "5. 이 과정을 반복한다.\n",
    "6. 마지막으로 테스트 데이터에서 성능을 측정한다. \n",
    "\n",
    "다음 번에 시도한 하이퍼파라미터를 선택하는 알고리즘이 이 과정의 핵심이다. 베이지안 최적화 유전 알고리즘, 간단한 랜덤 탐색 등이 있다.\n",
    "\n",
    "모델의 가중치를 학습하는 것은 비교적 쉽니다. 미니 배치 데이터에 대한 손실 함수 값을 계산하고 역전파 알고리즘을 사용하여 올바른 방향으로 가중치를 이동하면 된다. 반면에 하이퍼파라미터를 업데이트하는 것은 매우 어렵다.\n",
    "\n",
    "- 피드백 신호를 계산하는 것은 매우 비용이 많이 든다. 새로운 모델을 만들고 데이터셋을 사용하여 처음부터 다시 훈련해야 한다.\n",
    "- 하이퍼파라미터 공간은 일반적으로 분리되어 있는 결정들로 채워진다. 즉 연속적이지 않고 미분 가능하지 않다. 그러므로 하이퍼파라미터 공간에 경사 하강법을 사용할 수 없다. 훨씬 비효율적인 그래디언트-프리 최적화 기법을 사용해야 한다.\n",
    "\n",
    "가장 단순하지만 종종 랜덤 탐색이 제일 좋은 방법일 때가 많다. 이 보다 더 나은 도구는 [Hyperopt](https://github.com/hyperopt/hyperopt)이다. 이 라이브러리는 잘 작동할 것 같은 하이퍼파라미터 조합을 예측하기 위해 내부적으로 Parzen 트리 추정기를 사용한다. 다른 라이브러리로 [Hyperas](https://github.com/maxpumperla/hyperas)는 Hyperopt와 연동하여 케라스 모델에 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preda = 0.25 * (preds_a + preds_b + preds_c + preds_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preda = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c 0.15 * + preds_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존과 다른 다양한 모델을 사용하여 가중치를 조정하는 일이 필요하다. 다른 모델이 가지지 못한 정보를 제공하는 것이 앙상블의 핵심이다. 최상의 모델이 얼마나 좋은지보다 앙상블의 후보 모델이 얼마나 다양한지가 중요하다.\n",
    "\n",
    "딥러닝과 얕은 모델을 섞은 넓고 깊은 모델로 최근 실전에서 매우 성공적으로 적용되었다. 이런 모델은 심층 신경망과 많은 선형 모델을 함께 훈련한다. 다양한 종류의 모델을 함께 훈련하는 것은 모델 앙상블을 만드는 또다른 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
